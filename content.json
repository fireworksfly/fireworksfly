{"meta":{"title":"嘉爷の博客","subtitle":"","description":"记录自己平时遇到的问题","author":"NewRomantics","url":"http://newromantics.top","root":"/"},"pages":[{"title":"friends","date":"2023-01-31T03:36:25.000Z","updated":"2023-01-31T03:42:12.726Z","comments":true,"path":"friends/index.html","permalink":"http://newromantics.top/friends/index.html","excerpt":"","text":""},{"title":"","date":"2023-01-31T03:41:12.153Z","updated":"2023-01-31T03:41:12.153Z","comments":true,"path":"about/index.html","permalink":"http://newromantics.top/about/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2023-01-31T03:41:41.396Z","updated":"2023-01-31T03:41:41.396Z","comments":true,"path":"categories/index.html","permalink":"http://newromantics.top/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2023-01-31T03:42:34.056Z","updated":"2023-01-31T03:42:34.056Z","comments":true,"path":"tags/index.html","permalink":"http://newromantics.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"常用的模型评估指标","slug":"常用的模型评估指标","date":"2023-02-24T15:50:30.000Z","updated":"2023-03-18T16:07:03.324Z","comments":true,"path":"2023/02/24/常用的模型评估指标/","link":"","permalink":"http://newromantics.top/2023/02/24/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/","excerpt":"","text":"在模型的评估过程中，分类问题、排序问题、回归问题往往需要使用不同的指标进行评估。大部分的指标只能片面的反映模型的一部分性能，所以我们需要充分的了解这些指标，并且合理的运用它们。 准确率（Accuracy）准确率是最直观的评价指标，但是会存在明显的缺陷。比如当负样本的占比为99%时，分类器把所有样本预测为负样本也可以获得99%的准确率。所以当不同类别的样本非常不均衡的时候，占比大的类别往往会成为影响准确率的最主要因素。为了解决这个问题，可以使用平均准确率（每个类别下样本的准确率的算术平均）作为模型评估的指标。 准确率指的是分类正确的样本占总样本个数的比例，即 ​ $${Accuracy&#x3D;{n_{correct}\\over n_{total}}}$$ 精确率（Precision）和召回率(recall)精确率是指分类正确的正样本个数占模型判定为正样本的样本个数的比例。 召回率是指分类正确的正样本个数占真正的正样本个数的比例。 精确率和召回率的值既统一又矛盾的两个指标，统一在如果一个模型的效果那么这两个指标的值都会很高。矛盾在如果要提高精确率，模型会在很有把握的情况下才会把样本判定为正样本，但此时往往会因为过于保守而漏掉很多没有把握的正样本，导致召回率降低。所以通常评判一个模型的性能会通过P-R曲线图进行判断。只有通过P-R曲线的整体表现，才能够对模型进行更为全面的评估。 除此之外，F1score和ROC曲线也能综合地反映一个模型的性能。其中F1score是精准率和召回率的调和平均值，它的定义为 $${F1&#x3D;{2\\times precision \\times recall\\over {precision + recall}}}$$ 平方根误差（RMSE）​ $${RMSE&#x3D;\\sqrt[2]{\\frac{\\sum\\limits_{i &#x3D; 1}^n(y_{true} - y_{pred})^2}{n}}}$$ 一般情况下，RMSE能够很好地反映回归模型预测值与真实值的偏离程度。但是如果假如存在个别偏离程度非常大的离群点时，会让RMSE指标变得很差。 然后就出现了平均绝对百分比误差（MAPE）。 ​ $$ MAPE &#x3D; \\sum\\limits_{i &#x3D; 1}^n|\\frac{y_{true} - y_{pred}}{y_{true}}| \\times \\frac{100}{n}$$ 相比RMSE，MAPE相当于把每个点的误差进行了归一化，降低了个别离群点带来的绝对误差的影响。 ROC曲线介绍ROC曲线之前需要了解前置知识-混淆矩阵。 根据任务的需求的不同，之前的几个指标评估模型存在一定的局限性。可以通过混淆矩阵可以定义更多的衡量指标。 混淆矩阵 预测值 Positive Negative 真实值 Positive TP(真正例)FN(假反例) Negative FP(假正例) TN(真反例) 下面对四个部分进行说明： TP(True Positive，真正例)：将真实情况为正例的类型正确地预测为正例 FN(False Negative，假反例)：将真实情况为正例的类型错误地预测为反例 FP(False Positive，假正例)：将真实情况为反例的类型错误地预测为正例 TN(True Negative，真反例)：将真实情况为反例的类型正确地预测为反例 ROC的横坐标为假阳性率FPR（假正例）;纵坐标为真阳性率TPR（真正例）。FPR和TPR的计算方法分别为 ​ $$ FPR &#x3D; \\frac{FP}{N}$$ ​ $$ TPR &#x3D; \\frac{TP}{P}$$ 上面两个式子中，P代表真实的样本数量，N是真实的负样本数量，TP代表P个正样本中被模型预测为正样本的个数，FP是N个负样本中被模型预测为正样本的个数。 如何绘制ROC曲线呢？ 将FPR作为曲线的横轴，TPR作为曲线的纵轴，然后通过不断移动模型的’”截断点”，来生成一组组关键点，最后连接成线。具体做法就是样本按照预测概率从高到低排序，在输出正负例之前，指定一个阈值，预测概率大于该阈值的样本被判为正例，小于该阈值的样本被判为负例。这样就能得到一个坐标。然后不断改变阈值就能够得到很多点，最后将这些点连接成线就得到了ROC曲线。 还有一种更直观地绘制ROC曲线的方法：假设正样本的数量为P，负样本的数量为N；接下来，把横轴的刻度间隔设置为$\\frac{1}{N}$，纵轴的刻度间隔设置为$\\frac{1}{P}$;再根据模型输出的预测概率对样本由高到低进行排序；依次遍历样本，每遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，每遇到一个负样本就沿横轴方向绘制一个刻度的曲线，直到遍历完所有样本，曲线最终停在(1,1)这个点，这时整个ROC曲线绘制完成。 另外还有一个概念AUC，指的是ROC曲线与Y轴围成的面积大小，该值能够反映模型的性能。 ROC曲线与P-R曲线的比较相比于P-R曲线，ROC有一个特点，当正负样本的分布发生变化时，ROC曲线的形状能够基本保持不变，而P-R曲线的形状会发生剧烈变化。所以ROC曲线的适用场景更多。但是如果希望更多地看到模型在特定的数据集上的表现，P-R曲线能够更直观低反映其性能。 还有更多指标，未完待续…….","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://newromantics.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"判定模型和生成模型","slug":"判定模型和生成模型","date":"2023-01-31T09:40:34.000Z","updated":"2023-02-08T14:23:11.427Z","comments":true,"path":"2023/01/31/判定模型和生成模型/","link":"","permalink":"http://newromantics.top/2023/01/31/%E5%88%A4%E5%AE%9A%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"判定模型：根据x来”判别”Y， 求的是条件概率分布 生成模型：预测的根据是联合概率分布P(x，Y)，而联合概率可以理解为“生成”(x, Y)样本的概率分布。具体来说就是已知x,从Y的候选集合选出一个来，可能的样本有(x,Y1)、(x,Y2)，(x,Y3)…(x,Yn),实际数据是如何生成的依赖于P(x,Y)。最后选出“生成”概率最大的那个Yn。 总结：二者目的都是在使后验概率最大化，判定模型是直接对后验概率进行建模，但是生成模型通过贝叶斯定理这一“桥梁”使问题转化为求联合概率。说人话就是判定模型通过经验误差最小原则来决定决策边界。而生成模型通过统计学习各个类别的分布来决定决策边界。 上面的解释可能还不是说明清楚，之前在维基百科上看到一个很好的解释。 假设有四个样本 样本1 样本2 样本3 样本4 x 0 0 1 1 Y 0 0 0 1 生成模型的世界 Y&#x3D;0 Y&#x3D;1 x&#x3D;0 $\\frac{1}{2} $ 0 x&#x3D;1 $\\frac{1}{4} $ $\\frac{1}{4} $ $\\sum P(x, Y) &#x3D; 1 $ 判定模型的世界 Y&#x3D;0 Y&#x3D;1 x&#x3D;0 1 0 x&#x3D;1 $\\frac{1}{2} $ $\\frac{1}{2} $ $ \\sum_{y} P(Y|x)&#x3D;1 $ 常见的生成模型： 朴素贝叶斯、隐马尔可夫模型、高斯混合模型、文档主题生成模型（LDA）、限制玻尔兹曼机 常见的判别模型： k近邻算法、SVM、决策树、感知机、线性判别分析(LDA)、线性回归、传统的神经网络、条件随机场","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://newromantics.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"Python导入模块的搜索路径","slug":"Python导入模块的搜索路径","date":"2023-01-31T08:57:30.000Z","updated":"2023-01-31T14:33:13.742Z","comments":true,"path":"2023/01/31/Python导入模块的搜索路径/","link":"","permalink":"http://newromantics.top/2023/01/31/Python%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9D%97%E7%9A%84%E6%90%9C%E7%B4%A2%E8%B7%AF%E5%BE%84/","excerpt":"","text":"1、启动文件所在的目录 2、PYTHONPATH环境变量中配置的目录 3、标准库目录， 其实就是安装python时一起安装进系统的模块 4、lib\\site-packages下面.pth文件中指定的路径，以及下面自己扩展的第三方库 注：当前的Python工程所导入的模块必须在上述路径 上述的路径都会在python解释器启动的过程中被加载到sys.path中，所以也可以通过自行修改sys.path的内容来达到动态改变模块搜索路径目的。 123import syssys.path.append(&#x27;路径&#x27;)# 这样在导入其他模块就能够在sys.path中搜索到了","categories":[{"name":"python","slug":"python","permalink":"http://newromantics.top/categories/python/"}],"tags":[]}],"categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://newromantics.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"python","slug":"python","permalink":"http://newromantics.top/categories/python/"}],"tags":[]}